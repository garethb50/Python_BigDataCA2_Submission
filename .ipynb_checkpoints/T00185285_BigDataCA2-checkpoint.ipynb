{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Importing libraries and setting the dataset to a dataframe by reading the csv. \n",
    "# Sets the datatype of Customer ID and Invoice Id to string\n",
    "# Code and the description of what this code is doing has been taken from the sources below. \n",
    "# Some code has been modified.\n",
    "\n",
    "#https://www.kaggle.com/fabiendaniel/customer-segmentation/notebook\n",
    "#https://towardsdatascience.com/how-to-create-a-production-ready-recommender-system-3c932752f8ea\n",
    "#https://www.kaggle.com/povilass/analysis-of-transactions-from-a-bakery-and-apriori/data\n",
    "#https://medium.com/edureka/apriori-algorithm-d7cc648d4f1e\n",
    "#https://stackabuse.com/association-rule-mining-via-apriori-algorithm-in-python/\n",
    "#https://stackoverflow.com/questions/16970982/find-unique-rows-in-numpy-array\n",
    "#https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas\n",
    "import numpy as np # Linear algebra\n",
    "import pandas as pd # Data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore') # never print matching warnings\n",
    "import seaborn as sns # Advanced data visualization\n",
    "import datetime# module supplies classes for manipulating dates and times\n",
    "import matplotlib.pyplot as plt # Data visualization\n",
    "from mlxtend.frequent_patterns import apriori # Data pattern exploration\n",
    "from mlxtend.frequent_patterns import association_rules # Association rules conversion\n",
    "from scipy.sparse import lil_matrix # Row-based list of lists sparse matrix\n",
    "%matplotlib inline \n",
    "hybridSystemData = pd.read_csv('data.csv',encoding=\"ISO-8859-1\", dtype={'CustomerID': str,'InvoiceID': str})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InvoiceNo           0\n",
       "StockCode           0\n",
       "Description      1454\n",
       "Quantity            0\n",
       "InvoiceDate         0\n",
       "UnitPrice           0\n",
       "CustomerID     135080\n",
       "Country             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The sum of how many values in the dataframe are null\n",
    "hybridSystemData.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United Kingdom    495478\n",
       "Germany             9495\n",
       "France              8557\n",
       "EIRE                8196\n",
       "Spain               2533\n",
       "Name: Country, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at the top 5 countries where transactions were made and finding how many transactions were made in that country\n",
    "hybridSystemData.Country.value_counts().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Extracting all rows that contain transactions for the United Kingdom and all quantities that have values greater than 0. \n",
    "# This is because some of the quantities are returns and have negative values.Taking subset of the dataset\n",
    "hybridSystemData = hybridSystemData[hybridSystemData.Country == 'United Kingdom']\n",
    "hybridSystemData = hybridSystemData[hybridSystemData.Quantity >0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(486286, 8)\n",
      "United Kingdom    486286\n",
      "Name: Country, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Looking at the shape of the dataset\n",
    "print(hybridSystemData.shape)\n",
    "# Checking the count of uniques values \n",
    "print(hybridSystemData.Country.value_counts().head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['WHITE HANGING HEART T-LIGHT HOLDER', 'WHITE METAL LANTERN',\n",
       "       'CREAM CUPID HEARTS COAT HANGER', ...,\n",
       "       'CREAM HANGING HEART T-LIGHT HOLDER',\n",
       "       \"BLACK SIL'T SQU CANDLE PLATE \", 'PAPER CRAFT , LITTLE BIRDIE'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outputting the unique values in the Description column\n",
    "hybridSystemData['Description'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Dropping all null values in the CustomerID column\n",
    "hybridSystemData.dropna(axis = 0, subset = ['CustomerID'], inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Entries: 5118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(349227, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking how many duplicate entries are in the dataset, then dropping these.\n",
    "print('Duplicate Entries: {}'.format(hybridSystemData.duplicated().sum()))\n",
    "hybridSystemData.drop_duplicates(inplace = True)\n",
    "# Looking at the shape of the dataset after nulls and duplicate values have been dropped\n",
    "hybridSystemData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 349227 entries, 0 to 541893\n",
      "Data columns (total 8 columns):\n",
      "InvoiceNo      349227 non-null object\n",
      "StockCode      349227 non-null object\n",
      "Description    349227 non-null object\n",
      "Quantity       349227 non-null int64\n",
      "InvoiceDate    349227 non-null object\n",
      "UnitPrice      349227 non-null float64\n",
      "CustomerID     349227 non-null object\n",
      "Country        349227 non-null object\n",
      "dtypes: float64(1), int64(1), object(6)\n",
      "memory usage: 24.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Looking at the information on the dataset\n",
    "hybridSystemData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66859, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting only the first 20 transactions of each customer as the dataset is very big and may be easier to work with. \n",
    "# Assigning it to a new dataframe.\n",
    "hybridSystemData_CustomerIDLimit = pd.DataFrame(hybridSystemData.groupby(['CustomerID']).head(20))\n",
    "hybridSystemData_CustomerIDLimit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16649,)\n",
      "(3844,)\n"
     ]
    }
   ],
   "source": [
    "# Creating new array for invoices and description and assigning only uniques values in those columns to these\n",
    "invoices = hybridSystemData['InvoiceNo'].unique()\n",
    "description = hybridSystemData['Description'].unique()\n",
    "print(invoices.shape)\n",
    "print(description.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the description to a file for use later by the recommender system.\n",
    "# The csv was created for testing purposes so I could see in a clearer format what the index of an item is.\n",
    "pd.DataFrame(description).to_csv(\"descriptionArray.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O base indexing both the invoives and description as the id values are quite big\n",
    "# This indexing can be used for the Apriori algorithm but it would require the oputput to be convertyed back from item index description to the description\n",
    "# This is the process completed in the recommender system\n",
    "hybridSystemData_CustomerIDLimit['invoices'] = hybridSystemData_CustomerIDLimit['InvoiceNo'].apply(lambda x : np.argwhere(invoices == x)[0][0])\n",
    "hybridSystemData_CustomerIDLimit['description'] = hybridSystemData_CustomerIDLimit['Description'].apply(lambda x : np.argwhere(description == x)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot of the 20 most sold items\n",
    "fig, ax=plt.subplots(figsize=(16,7))\n",
    "hybridSystemData_CustomerIDLimit['StockCode'].value_counts().sort_values(ascending=False).head(20).plot.bar(width=0.5,edgecolor='k',align='center',linewidth=1)\n",
    "plt.xlabel('Stock Item',fontsize=20)\n",
    "plt.ylabel('Number of transactions',fontsize=17)\n",
    "ax.tick_params(labelsize=20)\n",
    "plt.title('20 Most Sold Items',fontsize=20)\n",
    "plt.grid()\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Using the datetime library to break up the Invoice date for visualisation purposes\n",
    "hybridSystemData_CustomerIDLimit['InvoiceDate'] = pd.to_datetime(hybridSystemData_CustomerIDLimit['InvoiceDate'])\n",
    "hybridSystemData_CustomerIDLimit['Week'] = hybridSystemData_CustomerIDLimit['InvoiceDate'].dt.week\n",
    "hybridSystemData_CustomerIDLimit['Month'] = hybridSystemData_CustomerIDLimit['InvoiceDate'].dt.month\n",
    "hybridSystemData_CustomerIDLimit['Weekday'] = hybridSystemData_CustomerIDLimit['InvoiceDate'].dt.weekday\n",
    "hybridSystemData_CustomerIDLimit['Hours'] = hybridSystemData_CustomerIDLimit['InvoiceDate'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputting the data now assigned using the datetime library\n",
    "hybridSystemData_CustomerIDLimit[['InvoiceDate','InvoiceNo', 'Month','Week', 'Weekday','Hours']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Assigning this datetime dataframe to a new dataframe\n",
    "df1=pd.DataFrame(hybridSystemData_CustomerIDLimit[['InvoiceDate','InvoiceNo', 'Month','Week', 'Weekday','Hours']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# A visualisation of the count of items purchased on each day of the week\n",
    "sns.countplot(x='Weekday',data=df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# A visualisatin of the count of items purcahsed during the hours of the day\n",
    "sns.countplot(x='Hours',data=df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Output of Both Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### APRIORI SYSTEM ######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the dataframe to a new dataframe\n",
    "aprioriData = pd.DataFrame(hybridSystemData_CustomerIDLimit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# A basket was created to store invoice number and description with all positive values converted to 1 and any values less than 0 are set to 0. \n",
    "basket = (aprioriData.groupby(['InvoiceNo', 'Description'])['Description']\n",
    "        .count().unstack().reset_index().fillna(0)\n",
    "        .set_index('InvoiceNo'))\n",
    "basket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# As there are alot of zeros in the data but we also need to make sure that any data that is greater than 0 is converted to 1\n",
    "# Any item not purchased in the invoice is set to 0\n",
    "def encode_units(x):\n",
    "    if x <= 0:\n",
    "        return 0\n",
    "    if x >= 1:\n",
    "        return 1\n",
    "basket_sets = basket.applymap(encode_units)\n",
    "basket_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We generate frequent basket sets that have support value greater than 0.016%. \n",
    "# This support can be lowered to return more products if needed (0.010 will output 26 values for the receommender system)\n",
    "frequent_itemsets = apriori(basket_sets, min_support=0.016, use_colnames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# We are now able to create rules with corresponding support, confidence and lift \n",
    "rules = association_rules(frequent_itemsets, metric='lift', min_threshold=1)\n",
    "rules.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe using standard pandas code, for a large lift (6) and high confidence (.8)\n",
    "rules[(rules['lift'] >= 6) & (rules['confidence'] >= 0.8) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# An array was created to store the first item in the rule for use later by the recommender system\n",
    "# The items that can be confidently predicted to be bought together are outputted.\n",
    "aprioriArray= []\n",
    "for item in rules.values.tolist():\n",
    "\n",
    "    pair0 = item[0] \n",
    "    items0 = [x for x in pair0]\n",
    "    pair1 = item[1] \n",
    "    items1 = [x for x in pair1]\n",
    "    aprioriArray.append(items0[0])\n",
    "    print(\"Item: \" + str(items0[0]) + \" -> \" + str(items1[0]))\n",
    "    print(\"Support: \" + str(item[4]))\n",
    "    print(\"Confidence: \" + str(item[5]))\n",
    "    print(\"Lift: \" + str(item[6]))\n",
    "    print(\"=====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outputing the value in the array\n",
    "print(aprioriArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the values from the csv file of item descriptions created earlier\n",
    "descriptionCSVData = pd.read_csv('descriptionArray.csv')\n",
    "\n",
    "# Setting column names in the dataframe\n",
    "descriptionCSVData.columns = ['baseIndex', 'baseDesc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the dataframe\n",
    "descriptionCSVData.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an array of item numbers for use in the comparison with the LLR output\n",
    "aprioriNumbers = []\n",
    "\n",
    "for i in np.unique(aprioriArray):\n",
    "    # Output the  description of the item\n",
    "    print(i)\n",
    "    aprioriNumbers.append(np.where(descriptionCSVData['baseDesc'].str.contains(i))[0][0])\n",
    "# Output the  indexes of the items in the numbers array\n",
    "print(aprioriNumbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### RECOMMENDER SYSTEM ######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new dataframe\n",
    "recData = pd.DataFrame(hybridSystemData_CustomerIDLimit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An occurrence lil_matrix is made from the values that are greater than 0 and this matrix is assigned with values from invoices and description columns\n",
    "occurences = lil_matrix((invoices.shape[0], description.shape[0]), dtype='int8')\n",
    "def set_occurences(invoice, description):\n",
    "    occurences[invoice, description] += 1\n",
    "recData.apply(lambda row: set_occurences(row['invoices'], row['description']), axis=1)\n",
    "occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A co-occurrence matrix is created from the occurrence matrix\n",
    "cooc = occurences.transpose().dot(occurences)\n",
    "cooc.setdiag(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The LLR algorithm used for the recommender system. This algorithm was proposed by Ted Dunning \n",
    "# The LLR computes the likelihood of two events, A and B appear together.\n",
    "\n",
    "# The parameters are\n",
    "\n",
    "#     k11, number of when both events appeared together\n",
    "#     k12, number of B appear without A\n",
    "#     k21, number of A appear without B\n",
    "#     k22, number of other things appeared without both of them\n",
    "def xLogX(x):\n",
    "    return x * np.log(x) if x != 0 else 0.0\n",
    "def entropy(x1, x2=0, x3=0, x4=0):\n",
    "    return xLogX(x1 + x2 + x3 + x4) - xLogX(x1) - xLogX(x2) - xLogX(x3) - xLogX(x4)\n",
    "def LLR(k11, k12, k21, k22):\n",
    "    rowEntropy = entropy(k11 + k12, k21 + k22)\n",
    "    columnEntropy = entropy(k11 + k21, k12 + k22)\n",
    "    matrixEntropy = entropy(k11, k12, k21, k22)\n",
    "    if rowEntropy + columnEntropy < matrixEntropy:\n",
    "        return 0.0\n",
    "    return 2.0 * (rowEntropy + columnEntropy - matrixEntropy)\n",
    "def rootLLR(k11, k12, k21, k22):\n",
    "    llr = LLR(k11, k12, k21, k22)\n",
    "    sqrt = np.sqrt(llr)\n",
    "    if k11 * 1.0 / (k11 + k12) < k21 * 1.0 / (k21 + k22):\n",
    "        sqrt = -sqrt\n",
    "    return sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The LLR is calculated for items and is saved to a pp_score matrix\n",
    "row_sum = np.sum(cooc, axis=0).A.flatten()\n",
    "column_sum = np.sum(cooc, axis=1).A.flatten()\n",
    "total = np.sum(row_sum, axis=0)\n",
    "pp_score = lil_matrix((cooc.shape[0], cooc.shape[1]), dtype='double')\n",
    "cx = cooc.tocoo()\n",
    "for i,j,v in zip(cx.row, cx.col, cx.data):\n",
    "    if v != 0:\n",
    "        k11 = v\n",
    "        k12 = row_sum[i] - k11\n",
    "        k21 = column_sum[j] - k11\n",
    "        k22 = total - k11 - k12 - k21\n",
    "        pp_score[i,j] = rootLLR(k11, k12, k21, k22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The results are sorted so that the highest LLR score on each item is on the first column of each row. \n",
    "result = np.flip(np.sort(pp_score.A, axis=1), axis=1)\n",
    "result_indices = np.flip(np.argsort(pp_score.A, axis=1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A minimum LLR score is given to remove insignificant indicators\n",
    "minLLR = 5\n",
    "indicators = result[:, :50]\n",
    "indicators[indicators < minLLR] = 0.0\n",
    "indicators_indices = result_indices[:, :50]\n",
    "max_indicator_indices = (indicators==0).argmax(axis=1)\n",
    "max = max_indicator_indices.max()\n",
    "indicators = indicators[:, :max+1]\n",
    "indicators_indices = indicators_indices[:, :max+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example of the indicators would be the score of item 1906(GREEN REGENCY TEACUP AND SAUCER).\n",
    "# The indicators for this are the items that are most likely to be bought together.\n",
    "# The higher the LLR score the mor likely they are to be bought together\n",
    "print(indicators[1906])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The description of the items  seen in the previous output\n",
    "# ROSES REGENCY TEACUP AND SAUCER has the highest LLR score so is the first item in the list of indicators\n",
    "description[indicators_indices[1906, :indicators[1906].nonzero()[0].shape[0]]].astype(\"str\").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Outputting the  items that appear in the Apriori output that also appear in the LLR output\n",
    "# Only the first item in the indicators was outputted as this would make the comparison with the Apriori output easier to see.\n",
    "# The LLR score of the first recommended item is outputted also\n",
    "z=1\n",
    "for i in aprioriNumbers:\n",
    "    \n",
    "    length = indicators[i].nonzero()[0].shape[0]\n",
    "    real_indicators = description[indicators_indices[i, :length]].astype(\"str\").tolist()\n",
    "    id = description[i]\n",
    "    \n",
    "    #print('Number : ', z,', id: ', id, ', indicators: ', real_indicators[0])\n",
    "    print(\"Item: \" + description[i] + \" -> \" + real_indicators[0])\n",
    "    print('LLR score ', indicators[i][0])\n",
    "    print(\"=====================================\")\n",
    "    z = z+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
